{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelTraining.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/r7b7Ox5xjBiLW4y9OLQ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivieromassi/Hysteresis-Modelling-with-Neural-Networks/blob/main/ModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx8pGEuYPTe_"
      },
      "source": [
        "Necessary imports to configure the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_uEUDq2O18J"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAC9MNyUP0BY"
      },
      "source": [
        "Getting the Dataset from the Github repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnK1MQxkPoQ5"
      },
      "source": [
        "!wget https://github.com/olivieromassi/Hysteresis-Modelling-with-Neural-Networks/raw/main/Dataset/P2_measurements.zip\n",
        "!unzip P2_measurements.zip -d P2_measurements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK1ZzgHZP-fj"
      },
      "source": [
        "The Hysteresis Dataset is downloaded from the Github repository and stored into a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz2izWQuP5ZL"
      },
      "source": [
        "cwd = \"/content/P2_measurements\"\n",
        "\n",
        "# Creating a dictionary containing all the measurements divided by frequency\n",
        "dataset = {}\n",
        "columns = [\"t\", \"B\", \"H\", \"-H\"] # t: timestamp, B: Magnetic Flux Density, H: Magnetic Field \n",
        "\n",
        "for file in os.listdir(cwd):\n",
        "    temp_data = pd.read_csv(os.path.join(cwd, file),sep=';', header=None, names=columns)\n",
        "    dataset[file] = temp_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq_-yhswO72h"
      },
      "source": [
        "# dRNN Model Training:\n",
        "\n",
        "This notebook contains the preliminary tests: different strategies to train the dRNN are here explored, trying to understand how to proceed.\n",
        "\n",
        "First, the model is trained over a single the Hysteresis loop measured for an input at a given frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmjPoqHDQK3F"
      },
      "source": [
        "# The loop corresponding to a triangular input at 1Hz is loaded\n",
        "train_df = dataset['P2_1Hz.CSV'][['H', 'B']]\n",
        "\n",
        "# The training set is normalized\n",
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cngs2EnlQLKX"
      },
      "source": [
        "The WindowGenerator Class can:\n",
        "\n",
        "1. Handle the indexes and offsets.\n",
        "2. Split windows of features into (features, labels) pairs.\n",
        "3. Efficiently generate batches of these windows from the training, evaluation, and test data, using `tf.data.Datasets`.\n",
        "\n",
        "The following code is inspired from https://www.tensorflow.org/tutorials/structured_data/time_series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YATa2RCbPl-B"
      },
      "source": [
        "class WindowGenerator():\n",
        "    def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=None, test_df=None,\n",
        "               label_columns=None, feature_columns=None):\n",
        "        # Store the raw data.\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.test_df = test_df\n",
        "\n",
        "        # Work out the label column indices.\n",
        "        self.label_columns = label_columns\n",
        "        if label_columns is not None:\n",
        "            self.label_columns_indices = {name: i for i, name in\n",
        "                                        enumerate(label_columns)}\n",
        "        self.feature_columns = feature_columns\n",
        "        self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "        # Work out the window parameters.\n",
        "        self.input_width = input_width\n",
        "        self.label_width = label_width\n",
        "        self.shift = shift\n",
        "\n",
        "        self.total_window_size = input_width + shift\n",
        "\n",
        "        self.input_slice = slice(0, input_width)\n",
        "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "        self.label_start = self.total_window_size - self.label_width\n",
        "        self.labels_slice = slice(self.label_start, None)\n",
        "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '\\n'.join([\n",
        "            f'Total window size: {self.total_window_size}',\n",
        "            f'Input indices: {self.input_indices}',\n",
        "            f'Label indices: {self.label_indices}',\n",
        "            f'Label column name(s): {self.label_columns}'])\n",
        "        \n",
        "    def split_window(self, features):\n",
        "        inputs = features[:, self.input_slice, :]\n",
        "        labels = features[:, self.labels_slice, :]\n",
        "        if self.label_columns is not None:\n",
        "            labels = tf.stack(\n",
        "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "                axis=-1)\n",
        "        # This customization allows to select the features to use as input, by properly setting\n",
        "        # the feature_columns argument   \n",
        "        if self.label_columns is not None:\n",
        "            inputs = tf.stack(\n",
        "                [inputs[:, :, self.column_indices[name]] for name in self.feature_columns],\n",
        "                axis=-1)\n",
        "        # Slicing doesn't preserve static shape information, so set the shapes\n",
        "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "        inputs.set_shape([None, self.input_width, None])\n",
        "        labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def make_dataset(self, data):\n",
        "        data = np.array(data, dtype=np.float32)\n",
        "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "                data=data,\n",
        "                targets=None,\n",
        "                sequence_length=self.total_window_size,\n",
        "                sequence_stride=1,\n",
        "                shuffle=False,\n",
        "                batch_size=20,)\n",
        "\n",
        "        ds = ds.map(self.split_window)\n",
        "\n",
        "        return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhFQF9CARtEh"
      },
      "source": [
        "# Instantiating a window class\n",
        "wide_window = WindowGenerator(\n",
        "    input_width=32, label_width=1, shift=0,\n",
        "    label_columns=['B'], feature_columns=['H'])\n",
        "\n",
        "wide_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3-_-EkYR7T6"
      },
      "source": [
        "# Building the tf.data.Dataset\n",
        "train_data = wide_window.make_dataset(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP1r19waSH_a"
      },
      "source": [
        "# Instantiating an iterator over the training dataset\n",
        "iterator = iter(train_data)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGhioSZfSI7o"
      },
      "source": [
        "features, labels = next(iterator)\n",
        "print(\"Features batch:\" + str(features))\n",
        "print(\"Labels batch:\" + str(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQliwbtYSV3T"
      },
      "source": [
        "class DiagonalRNNCell(tf.keras.layers.SimpleRNNCell):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(DiagonalRNNCell, self).__init__(recurrent_initializer='glorot_uniform',\n",
        "                                              **kwargs)\n",
        "    \n",
        "    # Overriding the build method \n",
        "    def build(self, input_shape):\n",
        "        super(DiagonalRNNCell, self).build(input_shape)\n",
        "\n",
        "        # Override only the recurrent kernel \n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            name='recurrent_kernel',\n",
        "            initializer=self.recurrent_initializer,\n",
        "            regularizer=self.recurrent_regularizer,\n",
        "            constraint=self.recurrent_constraint)\n",
        "\n",
        "    # Overriding the call method    \n",
        "    def call(self, inputs, states, training=None):\n",
        "        prev_output = states[0] if tf.nest.is_nested(states) else states\n",
        "        dp_mask = self.get_dropout_mask_for_cell(inputs, training)\n",
        "        rec_dp_mask = self.get_recurrent_dropout_mask_for_cell(\n",
        "            prev_output, training)\n",
        "\n",
        "        if dp_mask is not None:\n",
        "            h = tf.keras.backend.dot(inputs * dp_mask, self.kernel)\n",
        "        else:\n",
        "            h = tf.keras.backend.dot(inputs, self.kernel)\n",
        "        if self.bias is not None:\n",
        "            h = tf.keras.backend.bias_add(h, self.bias)\n",
        "\n",
        "        if rec_dp_mask is not None:\n",
        "            prev_output = prev_output * rec_dp_mask\n",
        "        # The Tensor product becomes a vector element-wise product\n",
        "        output = h + prev_output * self.recurrent_kernel\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "\n",
        "        new_state = [output] if tf.nest.is_nested(states) else output\n",
        "        return output, new_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O626IzdSZSC"
      },
      "source": [
        "# Example: building a dRNN using the custom cell\n",
        "\n",
        "cell = DiagonalRNNCell(units=256)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(20, 1,), batch_size=20)\n",
        "layer = tf.keras.layers.RNN(cell, stateful=True)(inputs) # To have cross-batch statefulness\n",
        "outputs = tf.keras.layers.Dense(1, activation='linear')(layer)\n",
        "\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='dRNN')\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USth8a7PScog"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.MSE, optimizer=tf.keras.optimizers.Adam(), metrics=[tf.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdUbB203SmAs"
      },
      "source": [
        "# Training the model for 10 epochs, resetting the states after each epoch.\n",
        "for i in range(10):\n",
        "    model.fit(train_data, epochs=1, verbose=2, batch_size=20)\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}